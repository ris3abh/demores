{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rishabhsharma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rishabhsharma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rishabhsharma/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import docx\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rishabh sharma\n",
      "data scientist \n",
      "philadelphia, pa| +1 (445) 260-7077 | rishabh.sharma1103@gmail.com | portfolio | linkedin | github\n",
      "\n",
      "education\n",
      "drexel university, college of computing and informatics\t\t\t\t\t\t\t     philadelphia, pa\n",
      "master of science in data science\t\t\t\t\t\t\t\t          \t\t               gpa: 3.83\n",
      "\n",
      "rajiv gandhi proudhyogik vishwavidyalaya\t\t\t\t\t\t                     \t\t          bhopal, india\n",
      "bachelor of technology in computer science and engineering\t\t\t\t\t         \t\t               gpa: 3.63\n",
      "\n",
      "skills \n",
      "programming languages & tools: python (numpy, pandas, plotly, tensorflow, pytorch, xgboost), r, sql, sas, excel\n",
      "data analytics & visualization: google analytics, power bi, tableau, crm analytics, looker\n",
      "big data & cloud technologies: spark, aws (s3, emr, sagemaker), azure, snowflake\n",
      "data management & integration: data extraction, manipulation, architecture, and warehousing techniques\n",
      "machine learning & deep learning: predictive modeling, statistical analysis, regression, clustering, forecasting, nlp, vertex ai \n",
      "software engineering & project management: docker, kubernetes, jenkins, tekton, typescript, react (mern stack), api development, agile.\n",
      "\n",
      "certifications\n",
      "•      aws certified data engineering associate (dea-c01) \n",
      "\n",
      "professional experience\n",
      "dark matter technologies                                                                        \t\t                              \t\t              jacksonville, florida\n",
      "data engineer\t\t\t\t\t\t\t\t\t               \t\t\t jul 2023 – de 2023\n",
      "collaborated with cross-functional teams including product owners, product managers, and end users to understand their business processes and needs, resulting in the development of customized ml models that improved customer facing retail search by 30%.\n",
      "utilized python and sql for building predictive models, achieving a 15% reduction in customer churn rate through tageted retention strategies based on data insights\n",
      "analyzed and processed large data sets using sql and nosql databases to drive innovative solutions for retail search, leading to a 40% increase in user engagement\n",
      "orchestrated the development of efficient etl pipelines for aiva vision technology, achieving a 14% cost reduction and a 23% increase in data processing efficiency\n",
      "\n",
      "digital pass\t\t\t\t\t\t\t\t\t\t     \t\t          indore, india\n",
      "data scientist\t\t\t\t\t\t\t\t\t        \t\t               jun 2021- jun 2022\n",
      "implemented efficient ml training workflows and learning pipelines via vertex ai, resulting in a 25% improvement in genai results accuracy\n",
      "developed and implemented machine learning applications, including nlp and llms, in a corporate environment using python and ml libraries like pytorch and tensorflow, resulting in a 20% increase in operational efficiency\n",
      "designed and built monitoring dashboards and alerts using splunk and dynatrace to track system performance, reducing downtime by 15% across all cloud-enabled solutions\n",
      "enhanced team communication by employing task management software, optimizing the tracking and coordination within the data engineering team for pivotal projects\n",
      "\n",
      "sk enterprises\t\t\t\t\t\t\t\t\t\t      \t\t         bhopal, india\t\n",
      "data scientist\t\t\t\t\t\t\t\t\t        \t\t            nov 2020 - jun 2021\n",
      "implemented advanced time series forecasting and lstm models for inventory management, resulting in a 25% reduction in overstock levels and a $500k cost savings\n",
      "utilized predictive analytics to optimize supply chain logistics, leading to a 20% decrease in delivery times and $300k in cost savings; showcased expertise in data-driven decision-making and operational efficiency within the retail industry\n",
      "executed critical enhancements for data processing, enhancing efficiency by 30% and reducing errors by 35%, demonstrating a strong commitment to accuracy and effectiveness\n",
      "\n",
      "academic projects (github)\n",
      "advertisement creator\n",
      "achieved a remarkable 97% accuracy rate in the generation of advertisements that resonated with target audiences, significantly reducing creative development time and tailoring content to user behavior and preferences\n",
      "seamlessly integrated the generative ai models with existing content management systems for on-the-fly ad creation fine-tuned for b2b sales and marketing\n",
      "\n",
      "mathematical equation solver using neural machine translation\n",
      "formulated a mathematical equation solver leveraging hugging face transformers and bi-lstm models, translating complex equations into solutions with an 80% accuracy rate by enriching the dataset to over 400,000 equations\n",
      "utilized nlp techniques for innovative mathematical language processing, significantly enhancing the model's ability to interpret and solve intricate mathematical equations, resulting in a validation accuracy boost of 80%\n",
      "\n",
      "sentencing prediction using docket data for court cases\n",
      "led the development of a sentencing prediction model employing ml/dl techniques on philadelphia court case data, achieving critical insights with an 81% accuracy rate in multiclass sentencing predictions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to extract text from a docx file\n",
    "def extract_text_from_docx(doc_path):\n",
    "    doc = docx.Document(doc_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    text = '\\n'.join(full_text)\n",
    "    # making them lower case\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "print(extract_text_from_docx('RISHABH SHARMA_01.docx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('utilized', 'JJ'), ('nlp', 'NN'), ('techniques', 'NNS'), ('for', 'IN'), ('innovative', 'JJ'), ('mathematical', 'JJ'), ('language', 'NN'), ('processing', 'NN'), (',', ','), ('significantly', 'RB'), ('enhancing', 'VBG'), ('the', 'DT'), ('model', 'NN'), (\"'s\", 'POS'), ('ability', 'NN'), ('to', 'TO'), ('interpret', 'VB'), ('and', 'CC'), ('solve', 'VB'), ('intricate', 'JJ'), ('mathematical', 'JJ'), ('equations', 'NNS'), (',', ','), ('resulting', 'VBG'), ('in', 'IN'), ('a', 'DT'), ('validation', 'NN'), ('accuracy', 'NN'), ('boost', 'NN'), ('of', 'IN'), ('80', 'CD'), ('%', 'NN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rishabhsharma/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "sentence = \"utilized nlp techniques for innovative mathematical language processing, significantly enhancing the model's ability to interpret and solve intricate mathematical equations, resulting in a validation accuracy boost of 80%\"\n",
    "tokens = word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Text containing mixed titles and pointers\n",
    "text = [\n",
    "            \"advertisement creator\",\n",
    "            \"achieved a remarkable 97% accuracy rate in the generation of advertisements that resonated with target audiences, significantly reducing creative development time and tailoring content to user behavior and preferences\",\n",
    "            \"seamlessly integrated the generative ai models with existing content management systems for on-the-fly ad creation fine-tuned for b2b sales and marketing\",\n",
    "            \"\",\n",
    "            \"mathematical equation solver using neural machine translation\",\n",
    "            \"formulated a mathematical equation solver leveraging hugging face transformers and bi-lstm models, translating complex equations into solutions with an 80% accuracy rate by enriching the dataset to over 400,000 equations\",\n",
    "            \"utilized nlp techniques for innovative mathematical language processing, significantly enhancing the model's ability to interpret and solve intricate mathematical equations, resulting in a validation accuracy boost of 80%\",\n",
    "            \"\",\n",
    "            \"sentencing prediction using docket data for court cases\",\n",
    "            \"led the development of a sentencing prediction model employing ml/dl techniques on philadelphia court case data, achieving critical insights with an 81% accuracy rate in multiclass sentencing predictions\",\n",
    "            \"\"\n",
    "        ]\n",
    "\n",
    "# Function to classify titles and pointers\n",
    "def classify_text(text):\n",
    "    results = {'titles': [], 'pointers': []}\n",
    "    for sent in text:\n",
    "        # if the sent has more than 7 words, it is a pointer, else it is a title\n",
    "        if len(sent.split()) > 7:\n",
    "            print(sent, \"is a pointer\")\n",
    "            results['pointers'].append(sent)\n",
    "        else:\n",
    "            print(sent, \"is a title\")\n",
    "            results['titles'].append(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.6.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.15)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
